{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import time\nimport numpy as np\nimport pandas as pd\nimport pandas_datareader as pdr\n\nfrom keras.layers import LSTM\nfrom keras.models import Sequential\nfrom keras.layers.wrappers import TimeDistributed\nfrom keras.layers.core import Dense, Activation, Dropout\n\nfrom sklearn.preprocessing import MinMaxScaler\n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas_datareader as pdr\ndef get_raw_data(index_name,retry_attempts = 3):   \n    if index_name:\n        while retry_attempts > 0 :\n            try:\n                df = pdr.get_data_yahoo(index_name)\n                new_df = df.reindex(index=pd.date_range(df.index.min(), \n                                          df.index.max(), \n                                          freq='D')).fillna(method='ffill')\n                retry_attempts = 0\n                return new_df\n            except:\n                print(\"Data pull failed. {} retry attempts remaining\".\\\n                      format(retry_attempts))\n                retry_attempts = retry_attempts - 1\n    else:\n        print(\"Invalid usage. Parameter index_name is required\")\n    return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sp_df = get_raw_data('^GSPC')\nsp_close_series = sp_df.Close\nplt.style.use('seaborn-poster')\nsp_close_series.plot(figsize=(15, 7), color = 'teal')\nsp_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sp_df.index.min(), sp_df.index.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"WINDOW = 6\nPRED_LENGTH = int(WINDOW/2)\ndef get_reg_train_test(timeseries,sequence_length= 51,\n                   train_size=0.9,roll_mean_window=5,\n                   normalize=True,scale=False):\n    # smoothen out series\n    if roll_mean_window:\n        timeseries = timeseries.rolling(roll_mean_window).mean().dropna()\n    \n    # create windows\n    result = []\n    for index in range(len(timeseries) - sequence_length):\n        result.append(timeseries[index: index + sequence_length])\n           \n    \n    # normalize data as a variation of 0th index\n    if normalize:\n        normalised_data = []\n        for window in result:\n            normalised_window = [((float(p) / float(window[0])) - 1) \\\n                                   for p in window]\n            normalised_data.append(normalised_window)\n        result = normalised_data\n    \n    # identify train-test splits\n    result = np.array(result) \n    row = round(train_size * result.shape[0])\n    \n    # split train and test sets\n    train = result[:int(row), :]\n    test = result[int(row):, :]\n    \n    # scale data in 0-1 range\n    scaler = None\n    if scale:\n        scaler=MinMaxScaler(feature_range=(0, 1))\n        train = scaler.fit_transform(train)\n        test = scaler.transform(test)\n      \n    # split independent and dependent variables  \n    x_train = train[:, :-1]\n    y_train = train[:, -1]\n        \n        \n    x_test = test[:, :-1]\n    y_test = test[:, -1]\n    \n    # Transforms for LSTM input\n    x_train = np.reshape(x_train, (x_train.shape[0], \n                                   x_train.shape[1], \n                                   1))\n    x_test = np.reshape(x_test, (x_test.shape[0], \n                                 x_test.shape[1], \n                                 1)) \n    \n    return x_train,y_train,x_test,y_test,scaler\n\n\n\n\n\n\nx_train,y_train,x_test,y_test,scaler = get_reg_train_test(sp_close_series,\n                                                      sequence_length=WINDOW+1,\n                                                      roll_mean_window=None,\n                                                      normalize=True,\n                                                      scale=False)\n    \nprint(\"Data Split Complete\")\n\nprint(\"x_train shape={}\".format(x_train.shape))\nprint(\"y_train shape={}\".format(y_train.shape))\nprint(\"x_test shape={}\".format(x_test.shape))\nprint(\"y_test shape={}\".format(y_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import LSTM\nfrom keras.models import Sequential\nfrom keras.layers.wrappers import TimeDistributed\nfrom keras.layers.core import Dense, Activation, Dropout\n\nfrom sklearn.preprocessing import MinMaxScaler\nimport time\n\ndef get_reg_model(layer_units=[100,100],dropouts=[0.2,0.2],window_size=50):\n    # build LSTM network\n    model = Sequential()\n    \n    # hidden layer 1\n    model.add(LSTM(layer_units[0], \n                   input_shape=(window_size,1), \n                   return_sequences=True))\n    model.add(Dropout(dropouts[0]))\n    \n    # hidden layer 2\n    model.add(LSTM(layer_units[1]))\n    model.add(Dropout(dropouts[1]))\n    \n    # output layer\n    model.add(Dense(1))\n    model.add(Activation(\"linear\"))\n    \n    start = time.time()\n    model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n    print(\"> Compilation Time : \", time.time() - start)\n    print(model.summary())\n    return model\n\nlstm_model=None\ntry:\n    lstm_model = get_reg_model(layer_units=[50,100],\n                           window_size=WINDOW)   \nexcept:\n    print(\"Model Build Failed. Trying Again\")\n    lstm_model = get_reg_model(layer_units=[50,100],\n                           window_size=WINDOW)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom sklearn.metrics import mean_squared_error\n\n\n\ncallbacks = [keras.callbacks.EarlyStopping(monitor='val_loss',\n                                           patience=2,\n                                           verbose=0)]\nlstm_model.fit(x_train, y_train, \n               epochs=20, batch_size=16,\n               verbose=1,validation_split=0.05,\n               callbacks=callbacks)\nprint(\"Model Fit Complete\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\ndef predict_reg_multiple(model, data, window_size=6, prediction_len=3):\n    prediction_list = []\n    \n    # loop for every sequence in the dataset\n    for window in range(int(len(data)/prediction_len)):\n        _seq = data[window*prediction_len]\n        predicted = []\n        # loop till required prediction length is achieved\n        for j in range(prediction_len):\n            predicted.append(model.predict(_seq[np.newaxis,:,:])[0,0])\n            _seq = _seq[1:]\n            _seq = np.insert(_seq, [window_size-1], predicted[-1], axis=0)\n        prediction_list.append(predicted)\n    return prediction_list\n\n\ntrain_pred_seqs = predict_reg_multiple(lstm_model,\n                                             x_train,\n                                             window_size=WINDOW,\n                                             prediction_len=PRED_LENGTH)\n\ntrain_offset = y_train.shape[0] - np.array(train_pred_seqs).flatten().shape[0]\n\ntrain_rmse = math.sqrt(mean_squared_error(y_train[train_offset:], \n                                          np.array(train_pred_seqs).\\\n                                          flatten()))\nprint('Train Score: %.2f RMSE' % (train_rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred_seqs = predict_reg_multiple(lstm_model,\n                                      x_test,\n                                      window_size=WINDOW,\n                                      prediction_len=PRED_LENGTH)\ntest_offset = y_test.shape[0] - np.array(test_pred_seqs).flatten().shape[0]\n\ntest_rmse = math.sqrt(mean_squared_error(y_test[test_offset:], \n                                          np.array(test_pred_seqs).\\\n                                          flatten()))\nprint('Test Score: %.2f RMSE' % (test_rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_reg_results(predicted_data, true_data, prediction_len=3):\n    fig = plt.figure(facecolor='white', figsize=(20, 9))\n    ax = fig.add_subplot(111)\n    \n    # plot actual data\n    ax.plot(true_data, \n            label='True Data',\n            c='black',alpha=0.3)\n    \n    # plot flattened data\n    plt.plot(np.array(predicted_data).flatten(), \n             label='Prediction_full',\n             c='c',linestyle='--')\n    \n    #plot each window in the prediction list\n    for i, data in enumerate(predicted_data):\n        padding = [None for p in range(i * prediction_len)]\n        plt.plot(padding + data, label='Prediction',c='black')\n\n    plt.title(\"Forecast Plot with Prediction Window={}\".format(prediction_len))\n    plt.show()\n\n\n\nplot_reg_results(test_pred_seqs,y_test,prediction_len=PRED_LENGTH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}